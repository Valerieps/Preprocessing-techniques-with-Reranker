{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"__run_complete_pipeline__LSA.ipynb","provenance":[],"collapsed_sections":["YQ4xwplIfcFp"],"mount_file_id":"1M8wFU88iMgfeGtXaQFsc5LE7YqZ6lVoB","authorship_tag":"ABX9TyOC0BIxhr31eTUx4ahHDARt"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"YQ4xwplIfcFp"},"source":["# Prepare environment"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eVGDEU9Bxayg","executionInfo":{"status":"ok","timestamp":1630866430867,"user_tz":180,"elapsed":390,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"}},"outputId":"c467a3f9-74a3-48dd-ffd2-c7ffd1dc97fd"},"source":["%cd /content/drive/MyDrive/__TCC__Reranker/Reranker"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/__TCC__Reranker/Reranker\n"]}]},{"cell_type":"code","metadata":{"id":"rw3dAZ1fUF5j","executionInfo":{"status":"ok","timestamp":1630866537007,"user_tz":180,"elapsed":106160,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"}}},"source":["%%capture\n","!pip install ipython-autotime\n","!pip install -e ."],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7OX2BaSULJt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630866537008,"user_tz":180,"elapsed":14,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"}},"outputId":"faf9227e-6110-49f4-a871-a2f261e27614"},"source":["%load_ext autotime"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 61.2 Âµs (started: 2021-09-05 18:28:58 +00:00)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIanP7153QPv","executionInfo":{"status":"ok","timestamp":1630866537008,"user_tz":180,"elapsed":10,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"}},"outputId":"10abf4d1-f2ef-471f-9d17-f38e2c9e5bc9"},"source":["!nvidia-smi"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Sep  5 18:28:58 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","time: 121 ms (started: 2021-09-05 18:28:58 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"33W5MoKVlD-z"},"source":["# Preprocessa arquivos de treino"]},{"cell_type":"code","metadata":{"id":"xeSdK8VZyJ6s"},"source":["!bash /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/scripts/run_preprocess_to_train.sh"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3DxNzSMHeqkk"},"source":["# Realiza treino"]},{"cell_type":"code","metadata":{"id":"LQBxU0u6LSzN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630876889236,"user_tz":180,"elapsed":10351901,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"}},"outputId":"1321fa69-40aa-485a-f460-6db24d1ed2f5"},"source":["!bash /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/scripts/run_5_train.sh"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["09/05/2021 18:29:06 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: True\n","09/05/2021 18:29:06 - INFO - __main__ -   Training/evaluation parameters RerankerTrainingArguments(output_dir='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_974', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=64, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=2.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Sep05_18-29-05_7ecdce6a6d67', logging_first_step=False, logging_steps=500, save_steps=2000, save_total_limit=None, no_cuda=False, seed=974, fp16=True, fp16_opt_level='O1', fp16_backend='auto', local_rank=0, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=8, past_index=-1, run_name='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_974', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, warmup_ratio=0.1, distance_cache=False, distance_cache_stride=2, collaborative=False)\n","09/05/2021 18:29:06 - INFO - __main__ -   Model parameters ModelArguments(model_name_or_path='bert-base-uncased', config_name=None, tokenizer_name=None, cache_dir=None, temperature=None)\n","09/05/2021 18:29:06 - INFO - __main__ -   Data parameters DataArguments(train_dir='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/training-files/', train_path=['/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/training-files/000.group.json'], train_group_size=8, dev_path=None, pred_path=None, pred_dir=None, pred_id_file=None, rank_score_path=None, max_len=512)\n","09/05/2021 18:29:06 - INFO - filelock -   Lock 140242358205968 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n","Downloading: 100% 570/570 [00:00<00:00, 596kB/s]\n","09/05/2021 18:29:06 - INFO - filelock -   Lock 140242358205968 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n","09/05/2021 18:29:06 - INFO - filelock -   Lock 140242358124304 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n","Downloading: 100% 232k/232k [00:00<00:00, 3.18MB/s]\n","09/05/2021 18:29:06 - INFO - filelock -   Lock 140242358124304 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n","09/05/2021 18:29:07 - INFO - filelock -   Lock 140242358120848 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n","Downloading: 100% 440M/440M [00:07<00:00, 59.2MB/s]\n","09/05/2021 18:29:14 - INFO - filelock -   Lock 140242358120848 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Downloading: 3.63kB [00:00, 3.36MB/s]       \n","Using custom data configuration default\n","Downloading and preparing dataset json/default-efe80fa9d06b805d (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-efe80fa9d06b805d/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514...\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-efe80fa9d06b805d/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514. Subsequent calls will reuse this data.\n","  0% 0/4000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","{'loss': 1.8261, 'learning_rate': 9.722222222222223e-06, 'epoch': 0.25}\n","{'loss': 1.3862, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.5}\n","{'loss': 1.3983, 'learning_rate': 6.944444444444445e-06, 'epoch': 0.75}\n","{'loss': 1.2987, 'learning_rate': 5.555555555555557e-06, 'epoch': 1.0}\n"," 50% 2000/4000 [16:27<16:26,  2.03it/s]09/05/2021 18:45:51 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_974/checkpoint-2000\n","{'loss': 0.8708, 'learning_rate': 4.166666666666667e-06, 'epoch': 1.25}\n","{'loss': 1.0109, 'learning_rate': 2.7777777777777783e-06, 'epoch': 1.5}\n","{'loss': 1.2508, 'learning_rate': 1.3888888888888892e-06, 'epoch': 1.75}\n","{'loss': 0.9036, 'learning_rate': 0.0, 'epoch': 2.0}\n","100% 4000/4000 [33:19<00:00,  2.03it/s]09/05/2021 19:02:43 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_974/checkpoint-4000\n","{'train_runtime': 2020.2374, 'train_samples_per_second': 1.98, 'epoch': 2.0}\n","100% 4000/4000 [33:40<00:00,  1.98it/s]\n","09/05/2021 19:03:04 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_974\n","09/05/2021 19:03:20 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: True\n","09/05/2021 19:03:20 - INFO - __main__ -   Training/evaluation parameters RerankerTrainingArguments(output_dir='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_061', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=64, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=2.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Sep05_19-03-19_7ecdce6a6d67', logging_first_step=False, logging_steps=500, save_steps=2000, save_total_limit=None, no_cuda=False, seed=61, fp16=True, fp16_opt_level='O1', fp16_backend='auto', local_rank=0, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=8, past_index=-1, run_name='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_061', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, warmup_ratio=0.1, distance_cache=False, distance_cache_stride=2, collaborative=False)\n","09/05/2021 19:03:20 - INFO - __main__ -   Model parameters ModelArguments(model_name_or_path='bert-base-uncased', config_name=None, tokenizer_name=None, cache_dir=None, temperature=None)\n","09/05/2021 19:03:20 - INFO - __main__ -   Data parameters DataArguments(train_dir='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/training-files/', train_path=['/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/training-files/000.group.json'], train_group_size=8, dev_path=None, pred_path=None, pred_dir=None, pred_id_file=None, rank_score_path=None, max_len=512)\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using custom data configuration default\n","Reusing dataset json (/root/.cache/huggingface/datasets/json/default-efe80fa9d06b805d/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n","  0% 0/4000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","{'loss': 1.8435, 'learning_rate': 9.722222222222223e-06, 'epoch': 0.25}\n","{'loss': 1.3608, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.5}\n","{'loss': 1.4562, 'learning_rate': 6.944444444444445e-06, 'epoch': 0.75}\n","{'loss': 1.3548, 'learning_rate': 5.555555555555557e-06, 'epoch': 1.0}\n"," 50% 2000/4000 [16:28<16:25,  2.03it/s]09/05/2021 19:20:02 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_061/checkpoint-2000\n","{'loss': 0.9296, 'learning_rate': 4.166666666666667e-06, 'epoch': 1.25}\n","{'loss': 0.9197, 'learning_rate': 2.7777777777777783e-06, 'epoch': 1.5}\n","{'loss': 1.0012, 'learning_rate': 1.3888888888888892e-06, 'epoch': 1.75}\n","{'loss': 0.9187, 'learning_rate': 0.0, 'epoch': 2.0}\n","100% 4000/4000 [33:19<00:00,  2.03it/s]09/05/2021 19:36:53 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_061/checkpoint-4000\n","{'train_runtime': 2022.841, 'train_samples_per_second': 1.977, 'epoch': 2.0}\n","100% 4000/4000 [33:42<00:00,  1.98it/s]\n","09/05/2021 19:37:16 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_061\n","09/05/2021 19:37:30 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: True\n","09/05/2021 19:37:30 - INFO - __main__ -   Training/evaluation parameters RerankerTrainingArguments(output_dir='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_280', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=64, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=2.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Sep05_19-37-30_7ecdce6a6d67', logging_first_step=False, logging_steps=500, save_steps=2000, save_total_limit=None, no_cuda=False, seed=280, fp16=True, fp16_opt_level='O1', fp16_backend='auto', local_rank=0, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=8, past_index=-1, run_name='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_280', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, warmup_ratio=0.1, distance_cache=False, distance_cache_stride=2, collaborative=False)\n","09/05/2021 19:37:30 - INFO - __main__ -   Model parameters ModelArguments(model_name_or_path='bert-base-uncased', config_name=None, tokenizer_name=None, cache_dir=None, temperature=None)\n","09/05/2021 19:37:30 - INFO - __main__ -   Data parameters DataArguments(train_dir='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/training-files/', train_path=['/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/training-files/000.group.json'], train_group_size=8, dev_path=None, pred_path=None, pred_dir=None, pred_id_file=None, rank_score_path=None, max_len=512)\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using custom data configuration default\n","Reusing dataset json (/root/.cache/huggingface/datasets/json/default-efe80fa9d06b805d/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n","  0% 0/4000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","{'loss': 1.7884, 'learning_rate': 9.722222222222223e-06, 'epoch': 0.25}\n","{'loss': 1.3848, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.5}\n","{'loss': 1.404, 'learning_rate': 6.944444444444445e-06, 'epoch': 0.75}\n","{'loss': 1.3195, 'learning_rate': 5.555555555555557e-06, 'epoch': 1.0}\n"," 50% 2000/4000 [16:27<16:28,  2.02it/s]09/05/2021 19:54:11 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_280/checkpoint-2000\n","{'loss': 0.9426, 'learning_rate': 4.166666666666667e-06, 'epoch': 1.25}\n","{'loss': 1.0302, 'learning_rate': 2.7777777777777783e-06, 'epoch': 1.5}\n","{'loss': 1.0744, 'learning_rate': 1.3888888888888892e-06, 'epoch': 1.75}\n","{'loss': 0.9105, 'learning_rate': 0.0, 'epoch': 2.0}\n","100% 4000/4000 [33:17<00:00,  2.03it/s]09/05/2021 20:11:01 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_280/checkpoint-4000\n","{'train_runtime': 2025.1688, 'train_samples_per_second': 1.975, 'epoch': 2.0}\n","100% 4000/4000 [33:45<00:00,  1.98it/s]\n","09/05/2021 20:11:29 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_280\n","09/05/2021 20:11:45 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: True\n","09/05/2021 20:11:45 - INFO - __main__ -   Training/evaluation parameters RerankerTrainingArguments(output_dir='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_666', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=64, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=2.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Sep05_20-11-44_7ecdce6a6d67', logging_first_step=False, logging_steps=500, save_steps=2000, save_total_limit=None, no_cuda=False, seed=666, fp16=True, fp16_opt_level='O1', fp16_backend='auto', local_rank=0, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=8, past_index=-1, run_name='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_666', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, warmup_ratio=0.1, distance_cache=False, distance_cache_stride=2, collaborative=False)\n","09/05/2021 20:11:45 - INFO - __main__ -   Model parameters ModelArguments(model_name_or_path='bert-base-uncased', config_name=None, tokenizer_name=None, cache_dir=None, temperature=None)\n","09/05/2021 20:11:45 - INFO - __main__ -   Data parameters DataArguments(train_dir='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/training-files/', train_path=['/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/training-files/000.group.json'], train_group_size=8, dev_path=None, pred_path=None, pred_dir=None, pred_id_file=None, rank_score_path=None, max_len=512)\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using custom data configuration default\n","Reusing dataset json (/root/.cache/huggingface/datasets/json/default-efe80fa9d06b805d/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n","  0% 0/4000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","{'loss': 1.7825, 'learning_rate': 9.722222222222223e-06, 'epoch': 0.25}\n","{'loss': 1.4209, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.5}\n","{'loss': 1.3364, 'learning_rate': 6.944444444444445e-06, 'epoch': 0.75}\n","{'loss': 1.3683, 'learning_rate': 5.555555555555557e-06, 'epoch': 1.0}\n"," 50% 2000/4000 [16:27<16:28,  2.02it/s]09/05/2021 20:28:26 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_666/checkpoint-2000\n","{'loss': 0.967, 'learning_rate': 4.166666666666667e-06, 'epoch': 1.25}\n","{'loss': 0.9646, 'learning_rate': 2.7777777777777783e-06, 'epoch': 1.5}\n","{'loss': 0.9521, 'learning_rate': 1.3888888888888892e-06, 'epoch': 1.75}\n","{'loss': 0.8554, 'learning_rate': 0.0, 'epoch': 2.0}\n","100% 4000/4000 [33:16<00:00,  2.03it/s]09/05/2021 20:45:15 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_666/checkpoint-4000\n","{'train_runtime': 2019.2733, 'train_samples_per_second': 1.981, 'epoch': 2.0}\n","100% 4000/4000 [33:39<00:00,  1.98it/s]\n","09/05/2021 20:45:38 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_666\n","09/05/2021 20:45:55 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: True\n","09/05/2021 20:45:55 - INFO - __main__ -   Training/evaluation parameters RerankerTrainingArguments(output_dir='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_999', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=64, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=2.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Sep05_20-45-55_7ecdce6a6d67', logging_first_step=False, logging_steps=500, save_steps=2000, save_total_limit=None, no_cuda=False, seed=999, fp16=True, fp16_opt_level='O1', fp16_backend='auto', local_rank=0, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=8, past_index=-1, run_name='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_999', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, warmup_ratio=0.1, distance_cache=False, distance_cache_stride=2, collaborative=False)\n","09/05/2021 20:45:55 - INFO - __main__ -   Model parameters ModelArguments(model_name_or_path='bert-base-uncased', config_name=None, tokenizer_name=None, cache_dir=None, temperature=None)\n","09/05/2021 20:45:55 - INFO - __main__ -   Data parameters DataArguments(train_dir='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/training-files/', train_path=['/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/training-files/000.group.json'], train_group_size=8, dev_path=None, pred_path=None, pred_dir=None, pred_id_file=None, rank_score_path=None, max_len=512)\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using custom data configuration default\n","Reusing dataset json (/root/.cache/huggingface/datasets/json/default-efe80fa9d06b805d/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n","  0% 0/4000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","{'loss': 1.7598, 'learning_rate': 9.722222222222223e-06, 'epoch': 0.25}\n","{'loss': 1.4195, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.5}\n","{'loss': 1.417, 'learning_rate': 6.944444444444445e-06, 'epoch': 0.75}\n","{'loss': 1.4075, 'learning_rate': 5.555555555555557e-06, 'epoch': 1.0}\n"," 50% 2000/4000 [16:27<16:27,  2.03it/s]09/05/2021 21:02:36 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_999/checkpoint-2000\n","{'loss': 0.9942, 'learning_rate': 4.166666666666667e-06, 'epoch': 1.25}\n","{'loss': 1.1008, 'learning_rate': 2.7777777777777783e-06, 'epoch': 1.5}\n","{'loss': 1.2014, 'learning_rate': 1.3888888888888892e-06, 'epoch': 1.75}\n","{'loss': 1.0747, 'learning_rate': 0.0, 'epoch': 2.0}\n","100% 4000/4000 [33:14<00:00,  2.03it/s]09/05/2021 21:19:23 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_999/checkpoint-4000\n","{'train_runtime': 2013.6041, 'train_samples_per_second': 1.986, 'epoch': 2.0}\n","100% 4000/4000 [33:33<00:00,  1.99it/s]\n","09/05/2021 21:19:42 - INFO - reranker.trainer -   Saving model checkpoint to /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_999\n","09/05/2021 21:19:55 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: True\n","09/05/2021 21:19:55 - INFO - __main__ -   Training/evaluation parameters RerankerTrainingArguments(output_dir='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_1028', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=64, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=2.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Sep05_21-19-55_7ecdce6a6d67', logging_first_step=False, logging_steps=500, save_steps=2000, save_total_limit=None, no_cuda=False, seed=1028, fp16=True, fp16_opt_level='O1', fp16_backend='auto', local_rank=0, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=8, past_index=-1, run_name='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_1028', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, warmup_ratio=0.1, distance_cache=False, distance_cache_stride=2, collaborative=False)\n","09/05/2021 21:19:55 - INFO - __main__ -   Model parameters ModelArguments(model_name_or_path='bert-base-uncased', config_name=None, tokenizer_name=None, cache_dir=None, temperature=None)\n","09/05/2021 21:19:55 - INFO - __main__ -   Data parameters DataArguments(train_dir='/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/training-files/', train_path=['/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/training-files/000.group.json'], train_group_size=8, dev_path=None, pred_path=None, pred_dir=None, pred_id_file=None, rank_score_path=None, max_len=512)\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using custom data configuration default\n","Reusing dataset json (/root/.cache/huggingface/datasets/json/default-efe80fa9d06b805d/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n","  0% 0/4000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","  4% 158/4000 [01:18<31:42,  2.02it/s]Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/__TCC__Reranker/Reranker/common_scripts/run_marco_original.py\", line 161, in <module>\n","    main()\n","  File \"/content/drive/MyDrive/__TCC__Reranker/Reranker/common_scripts/run_marco_original.py\", line 107, in main\n","    model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 888, in train\n","    tr_loss += self.training_step(model, inputs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1259, in training_step\n","    self.scaler.scale(loss).backward()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 185, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 127, in backward\n","    allow_unreachable=True)  # allow_unreachable flag\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n","    \"__main__\", mod_spec)\n","  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 261, in <module>\n","    main()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 254, in main\n","    process.wait()\n","  File \"/usr/lib/python3.7/subprocess.py\", line 1019, in wait\n","    return self._wait(timeout=timeout)\n","  File \"/usr/lib/python3.7/subprocess.py\", line 1653, in _wait\n","    (pid, sts) = self._try_wait(0)\n","  File \"/usr/lib/python3.7/subprocess.py\", line 1611, in _try_wait\n","    (pid, sts) = os.waitpid(self.pid, wait_flags)\n","KeyboardInterrupt\n","  4% 158/4000 [01:19<32:06,  1.99it/s]\n","time: 2h 52min 29s (started: 2021-09-05 18:28:59 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"gIe9cAKTTrBF"},"source":["# Preprocessa arquivos de eval"]},{"cell_type":"code","metadata":{"id":"zbtESny6TtbJ"},"source":["!bash /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/scripts/run_preprocess_to_eval.sh"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O2mcvAAxe_no"},"source":["# Realiza Inference on five checkpoints"]},{"cell_type":"code","metadata":{"id":"cqQsfC8-fBAX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630886836521,"user_tz":180,"elapsed":9947300,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"}},"outputId":"78b8961e-1c68-4994-bfe1-7963a99fdcc6"},"source":["!bash /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/scripts/run_5_inference.sh"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\\n================= Inference on 974 =================\n","\n","\n","AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAa\n","\n","==============================================\n","\n","=========== CONFIGURANDO AS COISAS ===========\n","\n","===============================\n","/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_974\n","\n","===========  GETTING DATASET ===========\n","\n","===========  INITIALIZING TRAINER ===========\n","\n","===========  PREDICTION ===========\n","Using custom data configuration default\n","Downloading and preparing dataset json/default-088ebd9686e13064 (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-088ebd9686e13064/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514...\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-088ebd9686e13064/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514. Subsequent calls will reuse this data.\n","100% 1563/1563 [32:51<00:00,  1.26s/it]\n","===========  TERMINOU ===========\n","100% 1563/1563 [32:52<00:00,  1.26s/it]\n","\\n================= Inference on 061 =================\n","\n","\n","AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAa\n","\n","==============================================\n","\n","=========== CONFIGURANDO AS COISAS ===========\n","\n","===============================\n","/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_061\n","\n","===========  GETTING DATASET ===========\n","\n","===========  INITIALIZING TRAINER ===========\n","\n","===========  PREDICTION ===========\n","Using custom data configuration default\n","Reusing dataset json (/root/.cache/huggingface/datasets/json/default-088ebd9686e13064/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n","100% 1563/1563 [32:51<00:00,  1.26s/it]\n","===========  TERMINOU ===========\n","100% 1563/1563 [32:51<00:00,  1.26s/it]\n","\\n================= Inference on 280 =================\n","\n","\n","AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAa\n","\n","==============================================\n","\n","=========== CONFIGURANDO AS COISAS ===========\n","\n","===============================\n","/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_280\n","\n","===========  GETTING DATASET ===========\n","\n","===========  INITIALIZING TRAINER ===========\n","\n","===========  PREDICTION ===========\n","Using custom data configuration default\n","Reusing dataset json (/root/.cache/huggingface/datasets/json/default-088ebd9686e13064/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n","100% 1563/1563 [32:49<00:00,  1.26s/it]\n","===========  TERMINOU ===========\n","100% 1563/1563 [32:50<00:00,  1.26s/it]\n","\\n================= Inference on 666 =================\n","\n","\n","AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAa\n","\n","==============================================\n","\n","=========== CONFIGURANDO AS COISAS ===========\n","\n","===============================\n","/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_666\n","\n","===========  GETTING DATASET ===========\n","\n","===========  INITIALIZING TRAINER ===========\n","\n","===========  PREDICTION ===========\n","Using custom data configuration default\n","Reusing dataset json (/root/.cache/huggingface/datasets/json/default-088ebd9686e13064/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n","100% 1563/1563 [32:50<00:00,  1.26s/it]\n","===========  TERMINOU ===========\n","100% 1563/1563 [32:50<00:00,  1.26s/it]\n","\\n================= Inference on 999 =================\n","\n","\n","AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAa\n","\n","==============================================\n","\n","=========== CONFIGURANDO AS COISAS ===========\n","\n","===============================\n","/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/checkpoints_999\n","\n","===========  GETTING DATASET ===========\n","\n","===========  INITIALIZING TRAINER ===========\n","\n","===========  PREDICTION ===========\n","Using custom data configuration default\n","Reusing dataset json (/root/.cache/huggingface/datasets/json/default-088ebd9686e13064/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n","100% 1563/1563 [32:49<00:00,  1.26s/it]\n","===========  TERMINOU ===========\n","100% 1563/1563 [32:50<00:00,  1.26s/it]\n","time: 2h 45min 47s (started: 2021-09-05 21:21:28 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"dXCxZJ5iP1aM"},"source":["# Run evaluation on the five scores"]},{"cell_type":"code","metadata":{"id":"rtpIJF0OPZWy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630886840526,"user_tz":180,"elapsed":4013,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"}},"outputId":"1d5a6d2f-4e9e-49d7-f6aa-472590a3152c"},"source":["!bash /content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/scripts/run_5_evaluation.sh"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\\n================= RUN EVALUATION ON SEED 974 =================\n","398 excluded qids loaded\n","Quantity of Documents ranked for each query is as expected. Evaluating\n","#####################\n","MRR @100: 0.07348370661033402\n","QueriesRanked: 1000\n","#####################\n","\\n================= RUN EVALUATION ON SEED 061 =================\n","398 excluded qids loaded\n","Quantity of Documents ranked for each query is as expected. Evaluating\n","#####################\n","MRR @100: 0.07382118311115825\n","QueriesRanked: 1000\n","#####################\n","\\n================= RUN EVALUATION ON SEED 280 =================\n","398 excluded qids loaded\n","Quantity of Documents ranked for each query is as expected. Evaluating\n","#####################\n","MRR @100: 0.07396210907460089\n","QueriesRanked: 1000\n","#####################\n","\\n================= RUN EVALUATION ON SEED 666 =================\n","398 excluded qids loaded\n","Quantity of Documents ranked for each query is as expected. Evaluating\n","#####################\n","MRR @100: 0.07797321781605641\n","QueriesRanked: 1000\n","#####################\n","\\n================= RUN EVALUATION ON SEED 1028 =================\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/__TCC__Reranker/Reranker/common_scripts/4_score_to_marco.py\", line 14, in <module>\n","    with open(args.score_file) as f:\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/eval/score_1028.txt'\n","398 excluded qids loaded\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/__TCC__Reranker/Reranker/common_scripts/6_msmarco_eval_2.py\", line 226, in <module>\n","    main()\n","  File \"/content/drive/MyDrive/__TCC__Reranker/Reranker/common_scripts/6_msmarco_eval_2.py\", line 218, in main\n","    metrics = compute_metrics_from_files(path_to_reference, path_to_candidate, exclude_qids)\n","  File \"/content/drive/MyDrive/__TCC__Reranker/Reranker/common_scripts/6_msmarco_eval_2.py\", line 179, in compute_metrics_from_files\n","    qids_to_ranked_candidate_documents = load_candidate(path_to_candidate)\n","  File \"/content/drive/MyDrive/__TCC__Reranker/Reranker/common_scripts/6_msmarco_eval_2.py\", line 88, in load_candidate\n","    with open(path_to_candidate, 'r') as f:\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/__TCC__Reranker/Reranker/run_lsa_summarization/data/eval/score_1028.txt.marco'\n","time: 3.93 s (started: 2021-09-06 00:07:16 +00:00)\n"]}]}]}