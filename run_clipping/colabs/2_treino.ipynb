{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"2_treino.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"15-ZfmEDkyQ7PKAmYcY2HPiKV3bqs0llG","authorship_tag":"ABX9TyMVXZiewBetc7qHEJIVQUFP"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eVGDEU9Bxayg","executionInfo":{"status":"ok","timestamp":1629667585232,"user_tz":180,"elapsed":3125,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"}},"outputId":"387671e7-8383-4865-c6bd-872ca792d612"},"source":["!pip install ipython-autotime\n","\n","%load_ext autotime"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting ipython-autotime\n","  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.0.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n","Installing collected packages: ipython-autotime\n","Successfully installed ipython-autotime-0.3.1\n","time: 1.83 ms (started: 2021-08-22 21:26:25 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"orHTAAtTDtO5"},"source":["# Instala a lib Reranker"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9WqOlyQ3DSEL","executionInfo":{"status":"ok","timestamp":1629667602452,"user_tz":180,"elapsed":17227,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"}},"outputId":"3fb6c053-ae0c-4d19-c3b2-37b36148bb5a"},"source":["%cd /content/drive/MyDrive/__TCC__Reranker/Reranker/\n","%pip install -e ."],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/__TCC__Reranker/Reranker\n","Obtaining file:///content/drive/MyDrive/__TCC__Reranker/Reranker\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from reranker==0.0.1) (1.9.0+cu102)\n","Collecting transformers>=4.0.0\n","  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 4.1 MB/s \n","\u001b[?25hCollecting datasets>=1.1.3\n","  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n","\u001b[K     |████████████████████████████████| 264 kB 72.4 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->reranker==0.0.1) (0.3.4)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->reranker==0.0.1) (0.70.12.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->reranker==0.0.1) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->reranker==0.0.1) (1.19.5)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 73.7 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->reranker==0.0.1) (1.1.5)\n","Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->reranker==0.0.1) (3.0.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->reranker==0.0.1) (4.6.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->reranker==0.0.1) (21.0)\n","Collecting fsspec>=2021.05.0\n","  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n","\u001b[K     |████████████████████████████████| 118 kB 90.4 MB/s \n","\u001b[?25hCollecting huggingface-hub<0.1.0\n","  Downloading huggingface_hub-0.0.15-py3-none-any.whl (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->reranker==0.0.1) (4.62.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets>=1.1.3->reranker==0.0.1) (3.7.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets>=1.1.3->reranker==0.0.1) (3.0.12)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets>=1.1.3->reranker==0.0.1) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->reranker==0.0.1) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->reranker==0.0.1) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->reranker==0.0.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->reranker==0.0.1) (2021.5.30)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 51.2 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 62.2 MB/s \n","\u001b[?25hCollecting huggingface-hub<0.1.0\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->reranker==0.0.1) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 67.4 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets>=1.1.3->reranker==0.0.1) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.1.3->reranker==0.0.1) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.1.3->reranker==0.0.1) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets>=1.1.3->reranker==0.0.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->reranker==0.0.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->reranker==0.0.1) (1.0.1)\n","Installing collected packages: xxhash, tokenizers, sacremoses, pyyaml, huggingface-hub, fsspec, transformers, datasets, reranker\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Running setup.py develop for reranker\n","Successfully installed datasets-1.11.0 fsspec-2021.7.0 huggingface-hub-0.0.12 pyyaml-5.4.1 reranker-0.0.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2 xxhash-2.0.2\n","time: 17.2 s (started: 2021-08-22 21:26:25 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXU35l1TpflB","executionInfo":{"status":"ok","timestamp":1629667602453,"user_tz":180,"elapsed":26,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"}},"outputId":"655fb237-38c8-4d0d-c0be-28071324ac7a"},"source":["!pwd"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/__TCC__Reranker/Reranker\n","time: 109 ms (started: 2021-08-22 21:26:42 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W-XzWmFkvuF-","executionInfo":{"elapsed":852,"status":"ok","timestamp":1629638533233,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"},"user_tz":180},"outputId":"71d8a5ae-3d08-466b-af22-874a4ba7786d"},"source":["!export HF_DATASETS_CACHE=\"/content/drive/My Drive/_RERANKER_/data\""],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["time: 109 ms (started: 2021-08-22 13:22:12 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"2ooKNj0eTWHh"},"source":["## Roda o treino do BERT"]},{"cell_type":"markdown","metadata":{"id":"JRBSoA9aFTM7"},"source":["* flag -m: run library module as a script  \n","* torch.distributed.launch: "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"O0kVGVCT2siz","executionInfo":{"elapsed":11,"status":"ok","timestamp":1629638533234,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"},"user_tz":180},"outputId":"dca4a982-daa2-4155-dc9a-03feec7720bf"},"source":["%pwd"],"execution_count":null,"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/__TCC__Reranker/Reranker'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["time: 4.9 ms (started: 2021-08-22 13:22:12 +00:00)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"TkgewcLH2hSJ","executionInfo":{"status":"ok","timestamp":1629667602453,"user_tz":180,"elapsed":18,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"}},"outputId":"591d2832-16a8-4e0f-f011-9dd0cf5a208c"},"source":["%cd ../\n","%cd /content/drive/MyDrive/__TCC__Reranker/Reranker\n","%pwd"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/__TCC__Reranker\n","/content/drive/MyDrive/__TCC__Reranker/Reranker\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/__TCC__Reranker/Reranker'"]},"metadata":{},"execution_count":4},{"output_type":"stream","text":["time: 6.93 ms (started: 2021-08-22 21:26:42 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rg4AI2jXB0Th","executionInfo":{"elapsed":201,"status":"ok","timestamp":1629643020241,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"},"user_tz":180},"outputId":"d1d49a1d-adf4-49d7-e46c-6fbd805d8e0f"},"source":["%ls run_msmarco/data"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34m01-hdct-marco-train\u001b[0m/                   \u001b[01;34m04-inference_files\u001b[0m/\n","\u001b[01;34m02-msmarco-files\u001b[0m/                      \u001b[01;34m05-eval\u001b[0m/\n","\u001b[01;34m03.1-preprocessed_files_for_training\u001b[0m/  \u001b[01;34mminidata\u001b[0m/\n","\u001b[01;34m03.2-preprocesses_files_for_training\u001b[0m/  \u001b[01;34msamples\u001b[0m/\n","time: 116 ms (started: 2021-08-22 14:36:59 +00:00)\n"]}]},{"cell_type":"code","metadata":{"id":"H8lorpY_Nj0H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629667602454,"user_tz":180,"elapsed":15,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"}},"outputId":"3df2dc9d-2bbb-450c-eb2c-b28235149ac8"},"source":["import datetime\n","import pytz\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["time: 672 µs (started: 2021-08-22 21:26:42 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UMkq8H3SHAlu","executionInfo":{"status":"ok","timestamp":1629667602456,"user_tz":180,"elapsed":15,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"}},"outputId":"4995fc4d-dbcd-4350-a747-5178d82757a4"},"source":["# a timestamp I'd like to convert\n","my_timestamp = datetime.datetime.now()\n","\n","# create both timezone objects\n","old_timezone = pytz.timezone(\"Etc/Greenwich\")\n","new_timezone = pytz.timezone(\"America/Sao_Paulo\")\n","\n","# two-step process\n","localized_timestamp = old_timezone.localize(my_timestamp)\n","new_timezone_timestamp = localized_timestamp.astimezone(new_timezone)\n","print(new_timezone_timestamp)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["2021-08-22 18:26:42.613069-03:00\n","time: 26.6 ms (started: 2021-08-22 21:26:42 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pC684TNLMU67"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4mZqFugYkXBW","executionInfo":{"status":"ok","timestamp":1629669645133,"user_tz":180,"elapsed":2020038,"user":{"displayName":"valeria souza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjy1ubWOCSn_pFsyRc2CSUvWRhvnudvdntwRGWJWA=s64","userId":"02178959196389693763"}},"outputId":"e8a36cbd-09df-42bc-bfbd-c21e8b93f997"},"source":["!python -m torch.distributed.launch \\\n","  --nproc_per_node 1 run_msmarco/scripts/2_run_marco.py \\\n","  --output_dir run_msmarco/data/exp1_onefile_checkpoints \\\n","  --model_name_or_path  bert-base-uncased \\\n","  --do_train \\\n","  --save_steps 2000 \\\n","  --train_dir run_msmarco/data/exp1_onefile_training_files/ \\\n","  --max_len 512 \\\n","  --fp16 \\\n","  --per_device_train_batch_size 1 \\\n","  --train_group_size 8 \\\n","  --gradient_accumulation_steps 1 \\\n","  --per_device_eval_batch_size 64 \\\n","  --warmup_ratio 0.1 \\\n","  --weight_decay 0.01 \\\n","  --learning_rate 1e-5 \\\n","  --num_train_epochs 2 \\\n","  --overwrite_output_dir \\\n","  --dataloader_num_workers 8 \\"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:164: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n","  \"The module torch.distributed.launch is deprecated \"\n","The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run\n","WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.\n"," Please read local_rank from `os.environ('LOCAL_RANK')` instead.\n","INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:\n","  entrypoint       : run_msmarco/scripts/2_run_marco.py\n","  min_nodes        : 1\n","  max_nodes        : 1\n","  nproc_per_node   : 1\n","  run_id           : none\n","  rdzv_backend     : static\n","  rdzv_endpoint    : 127.0.0.1:29500\n","  rdzv_configs     : {'rank': 0, 'timeout': 900}\n","  max_restarts     : 3\n","  monitor_interval : 5\n","  log_dir          : None\n","  metrics_cfg      : {}\n","\n","INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_rz5k5392/none__n_gqawi\n","INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3\n","INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n","/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\n","  \"This is an experimental API and will be changed in future.\", FutureWarning\n","INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n","  restart_count=0\n","  master_addr=127.0.0.1\n","  master_port=29500\n","  group_rank=0\n","  group_world_size=1\n","  local_ranks=[0]\n","  role_ranks=[0]\n","  global_ranks=[0]\n","  role_world_sizes=[1]\n","  global_world_sizes=[1]\n","\n","INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n","INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_rz5k5392/none__n_gqawi/attempt_0/0/error.json\n","\n","\n","AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAa\n","\n","=========== CONFIGURANDO AS COISAS ===========\n","Downloading: 100% 570/570 [00:00<00:00, 484kB/s]\n","Downloading: 100% 28.0/28.0 [00:00<00:00, 27.1kB/s]\n","Downloading: 100% 232k/232k [00:00<00:00, 424kB/s]\n","Downloading: 100% 466k/466k [00:00<00:00, 645kB/s]\n","Downloading: 100% 440M/440M [00:06<00:00, 65.9MB/s]\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","===========  GETTING DATASET ===========\n","Using custom data configuration default-2dbc1ab8e89a978d\n","Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-2dbc1ab8e89a978d/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264...\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-2dbc1ab8e89a978d/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264. Subsequent calls will reuse this data.\n","\n","===========  INITIALIZING TRAINER ===========\n","Using amp fp16 backend\n","\n","===========  TRAINING ===========\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1032: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","***** Running training *****\n","  Num examples = 2000\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 1\n","  Total train batch size (w. parallel, distributed & accumulation) = 1\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4000\n","  0% 0/4000 [00:00<?, ?it/s][W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n","/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1316: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","{'loss': 1.7943, 'learning_rate': 9.736111111111112e-06, 'epoch': 0.25}\n","{'loss': 1.6184, 'learning_rate': 8.352777777777778e-06, 'epoch': 0.5}\n","{'loss': 1.449, 'learning_rate': 6.963888888888889e-06, 'epoch': 0.75}\n","{'loss': 1.4583, 'learning_rate': 5.577777777777778e-06, 'epoch': 1.0}\n"," 50% 2000/4000 [16:18<16:17,  2.05it/s]Configuration saved in run_msmarco/data/exp1_onefile_checkpoints/checkpoint-2000/config.json\n","Model weights saved in run_msmarco/data/exp1_onefile_checkpoints/checkpoint-2000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","{'loss': 1.2309, 'learning_rate': 4.188888888888889e-06, 'epoch': 1.25}\n"," 70% 2794/4000 [22:53<09:49,  2.05it/s]/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1316: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","  args.max_grad_norm,\n","{'loss': 1.3048, 'learning_rate': 2.802777777777778e-06, 'epoch': 1.5}\n","{'loss': 1.2868, 'learning_rate': 1.4138888888888891e-06, 'epoch': 1.75}\n","{'loss': 1.0467, 'learning_rate': 2.5000000000000002e-08, 'epoch': 2.0}\n","100% 4000/4000 [32:42<00:00,  2.05it/s]Configuration saved in run_msmarco/data/exp1_onefile_checkpoints/checkpoint-4000/config.json\n","Model weights saved in run_msmarco/data/exp1_onefile_checkpoints/checkpoint-4000/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 1969.0265, 'train_samples_per_second': 2.031, 'train_steps_per_second': 2.031, 'train_loss': 1.3986522521972655, 'epoch': 2.0}\n","100% 4000/4000 [32:49<00:00,  2.03it/s]\n","Configuration saved in run_msmarco/data/exp1_onefile_checkpoints/config.json\n","Model weights saved in run_msmarco/data/exp1_onefile_checkpoints/pytorch_model.bin\n","tokenizer config file saved in run_msmarco/data/exp1_onefile_checkpoints/tokenizer_config.json\n","Special tokens file saved in run_msmarco/data/exp1_onefile_checkpoints/special_tokens_map.json\n","\n","===========  TERMINOU ===========\n","INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n","INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish\n","/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/utils/store.py:71: FutureWarning: This is an experimental API and will be changed in future.\n","  \"This is an experimental API and will be changed in future.\", FutureWarning\n","INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.0003445148468017578 seconds\n","{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 0, \"group_rank\": 0, \"worker_id\": \"327\", \"role\": \"default\", \"hostname\": \"b73461872b8b\", \"state\": \"SUCCEEDED\", \"total_run_time\": 2016, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [0], \\\"role_rank\\\": [0], \\\"role_world_size\\\": [1]}\", \"agent_restarts\": 0}}\n","{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"AGENT\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": null, \"group_rank\": 0, \"worker_id\": null, \"role\": \"default\", \"hostname\": \"b73461872b8b\", \"state\": \"SUCCEEDED\", \"total_run_time\": 2016, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\"}\", \"agent_restarts\": 0}}\n","time: 33min 39s (started: 2021-08-22 21:27:05 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z-n8_C8mS67D"},"source":[""],"execution_count":null,"outputs":[]}]}